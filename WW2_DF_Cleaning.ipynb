{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/World_War_II_casualties'\n",
    "dfs = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localize CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[1]\n",
    "df.columns = df.iloc[0]\n",
    "df.drop(0).copy().to_csv('Human_losses_by_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[2]\n",
    "df = df.iloc[2:8]\n",
    "df.columns = df.iloc[0]\n",
    "df.drop(2).to_csv('Third_Reich_losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[4]\n",
    "df.columns = df.iloc[0]\n",
    "df.drop(0).to_csv('Soviet_losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[5]\n",
    "df.columns = df.iloc[0]\n",
    "df.drop(0).to_csv('Holocaust_Jews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[6]\n",
    "df.columns = df.iloc[0]\n",
    "df.drop(0).to_csv('Holocaust_Roma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[7]\n",
    "df.columns = df.iloc[0]\n",
    "df.drop(0).to_csv('Casualties_by_Branch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: csvs: File exists\n",
      "mv: rename *.csv to ./csvs/*.csv: No such file or directory\n",
      "Untitled.ipynb \u001b[34mcsvs\u001b[m\u001b[m\n",
      "Casualties_by_Branch.csv    Human_losses_by_country.csv\n",
      "Holocaust_Jews.csv          Soviet_losses.csv\n",
      "Holocaust_Roma.csv          Third_Reich_losses.csv\n"
     ]
    }
   ],
   "source": [
    "!mkdir csvs\n",
    "!mv *.csv ./csvs/\n",
    "!ls\n",
    "!ls csvs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_footnote(df, columns, num_footnotes):\n",
    "    tmp = df.copy()\n",
    "    pattern = re.compile(r'(.*)(\\[.*\\])(.*)')\n",
    "    \n",
    "    for _ in range(num_footnotes):\n",
    "        for column in columns:\n",
    "            tmp[column] = [pattern.sub(r'\\1 \\3', str(elem)) for elem in tmp[column]]\n",
    "    return tmp\n",
    "\n",
    "def spot_removal(df, columns):\n",
    "    #Removes 'AB' from AmericaAB (note)AB\n",
    "    #Removes 'A2' from (table)A2\n",
    "    tmp = df.copy()\n",
    "    pattern = re.compile(r'(.*[^A-Z])([A-Z]?[A-Z][0-9]?)$')\n",
    "    pattern2 = re.compile(r'(.*[^A-Z])([A-Z]?[A-Z][0-9]?)(\\s*\\(.*\\))')\n",
    "    pattern3 = re.compile(r'(United Kingdom)(BE) (including Crown Colonies)')\n",
    "    \n",
    "    for column in columns:\n",
    "        tmp[column] = [pattern.sub(r'\\1', str(elem)) for elem in tmp[column]]\n",
    "        tmp[column] = [pattern2.sub(r'\\1\\3', str(elem)) for elem in tmp[column]]\n",
    "        tmp[column] = [pattern3.sub(r'\\1 (\\3)', str(elem)) for elem in tmp[column]]\n",
    "    return tmp\n",
    "\n",
    "def remove_commas(df, columns):\n",
    "    df_noComma = pd.DataFrame()\n",
    "    for elem in columns:\n",
    "        df_noComma[elem] = df[elem].str.replace(',', '')\n",
    "    return df_noComma\n",
    "\n",
    "def split_xtoy(df, columns):\n",
    "    df = df.copy()\n",
    "    pattern = re.compile(r'(\\D*)(\\d*\\.?\\d*)(\\D*)(\\d*\\.?\\d*)(\\D*)')\n",
    "    for column in columns:\n",
    "        df[column+'_min'] = [pattern.sub(r'\\2', str(elem)) for elem in df[column]]\n",
    "        df[column+'_max'] = [pattern.sub(r'\\4', str(elem)) for elem in df[column]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human losses by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./csvs/Human_losses_by_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cleaned = remove_footnote(df, df.columns, 10)\n",
    "df_cleaned = spot_removal(df_cleaned, df.columns)\n",
    "df_cleaned = remove_commas(df_cleaned, df.columns)\n",
    "df_minmax = split_xtoy(df_cleaned, df.columns[2:])\n",
    "df_cleaned = df_minmax.replace(r'^\\s*$', np.nan, regex=True) #replaces whitespace with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HLBC = df_cleaned[df_cleaned.columns[:2].append(df_cleaned.columns[8:])]\n",
    "df_HLBC[df_HLBC.columns[1:]] = df_HLBC[df_HLBC.columns[1:]].astype(float, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localize Clean CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: clean_csvs: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir clean_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HLBC.to_csv('./clean_csvs/Human_losses_by_country_CLEAN.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
